# PROJECT.md - Budget & Hochrechnung Automation PoC

## Projektziel
**Automatisierte Budget-Pipeline mit intelligenter Validierung und Versionsverwaltung**

Vereinfachung von Hochrechnungs- und Budget-Prozessen durch:
- âœ… Validierte Datenverarbeitung (pointblanc)
- âœ… Reproduzierbare Berechnungen (Formelwerk implementiert)
- ğŸ”„ **NEW**: Intelligente targets-Pipeline mit selektivem Caching
- ğŸ¨ **NEW**: Interaktives Shiny-Dashboard mit Versions-Vergleich

---

## Datenmodell

### Produkte (Join-Key)
**Ambulant**: `Amb_T`, `Amb_S`, `Amb_C`  
**StationÃ¤r**: `Hosp_P`, `Hosp_HP`

### Input-Dateien (mit Versionierung)
Alle Inputdateien nutzen Namenskonvention: `Input_<Name>_v<NN>.csv`

| Datei | Spalten | Beschreibung |
|-------|---------|-------------|
| `Input_Hochrechnung_v*.csv` | `product_id`, `bestand`, `bvp`, `nvl` | Ist-Bestand, Betrag pro Versicherte & Schadenwert |
| `Input_Rabatt_v*.csv` | `product_id`, `fam_rab`, `mj_rab` | Familienrabatt & MehrjÃ¤hrig-Rabatt (%) |
| `Input_Betriebskosten_v*.csv` | `product_id`, `sm`, `bk` | Saison-Multiplikator & Betriebskosten |
| `Input_SAP_v*.csv` | `product_id`, `advo`, `pd`, `sap` | Ist-Daten (Advocacy, Pd, SAP-Betrag) |

### Formelwerk
```
nvp = bvp - (fam_rab + mj_rab)           # Netto-VersicherungsprÃ¤mie
SQ = nvl / nvp                            # Schadenquote (Ziel: 60-80%)
vp = nvp - advo - pd                      # Verdiente PrÃ¤mie
va = nvl + sap + sm                       # Versicherungs-Aufwand
CR = (va + bk) / vp                       # Combined Ratio (Ziel: 85-105%)
```

---

## Workflow & Versioning

### Standard-Flow mit targets-Pipeline

1. **Input Generation** (manuell)
   - Neue CSV-Dateien werden in `data/raw/` abgelegt
   - Versionierungskonvention: `Input_<Name>_v<NN>.csv`
   - Beispiel: `Input_Rabatt_v001.csv`, `Input_Rabatt_v002.csv`

2. **Automatische Pipeline-Trigger** (targets)
   ```
   tar_make()  # Erkennt DateiÃ¤nderungen, berechnet nur notwendiges neu
   ```
   
3. **Intelligentes Caching**
   - targets vergleicht Timestamps der Input-Dateien mit letztem Report
   - **Nur geÃ¤nderte Inputs** triggern Neuberechnung
   - UnverÃ¤nderte Inputs werden aus Cache wiederverwendet
   - Beispiel: Wenn nur `Input_Rabatt_v002.csv` neu ist, aber Hochrechnung, Betriebskosten und SAP gleichbleiben â†’ nur Rabatt wird neu geladen

4. **Validierung & Berechnung**
   - Alle geladenen Inputs durchlaufen pointblanc-Validierung
   - Bei Fehler: Pipeline stoppt mit aussagekrÃ¤ftiger Fehlermeldung
   - Bei OK: Formelwerk berechnet KPIs (nvp, SQ, vp, va, CR)

5. **Output Generation**
   - Quarto-Report wird generiert: `output/report_<timestamp>.html`
   - Rohdaten exportiert: `output/results_<timestamp>.csv`
   - Metadaten gespeichert: `output/.metadata.json` (Input-Versionen, Timestamps)

---

## Architektur & Tech-Stack

### PoC (GitHub)
```
poc_positron_posit_connect/
â”œâ”€â”€ R/
â”‚   â”œâ”€â”€ 00_config.R              # Konstanten & Konfiguration
â”‚   â”œâ”€â”€ 01_load_data.R           # CSV-Laden mit Error-Handling âœ…
â”‚   â”œâ”€â”€ 02_validate_data.R       # pointblanc-Regeln âœ…
â”‚   â”œâ”€â”€ 03_calculate.R           # Formelwerk âœ…
â”‚   â””â”€â”€ 04_reporting.R           # (Optional) Report-Hilfsfunktionen
â”œâ”€â”€ _targets.R                   # ğŸ”„ targets-Pipeline (TODO)
â”œâ”€â”€ report.qmd                   # Quarto-Report (TODO)
â”œâ”€â”€ app.R                        # (Optional) Shiny-Dashboard
â”œâ”€â”€ data/raw/                    # Input-CSVs mit Versionierung
â”œâ”€â”€ output/                      # Generierte Reports & Daten
â””â”€â”€ test/                        # ğŸ”’ ISOLIERT: Unit & Integration Tests
                                 # (Nicht Teil der Pipeline-Ã„nderungen)
```

### Tech-Stack
- **Datenvalidation**: pointblanc (Custom Business Rules)
- **Workflow-Orchestrierung**: `targets` (DAG + intelligentes Caching)
- **Output-Format**: Quarto (.qmd â†’ HTML Report)
- **Testing**: testthat
- **Versionskontrolle**: Git (mit semantischen Commit Messages)

---

## ğŸ”„ targets-Pipeline Challenge

### Kernaufgabe: Intelligentes Caching mit Partial Updates

**Problem**: 
Die Pipeline hat 4 Input-Dateien mit  unterschiedlichen Versionen. Nicht alle mÃ¼ssen gleichzeitig aktualisiert werden.
Beispiel:
- `Input_Hochrechnung_v001.csv` (aktuell)
- `Input_Rabatt_v002.csv` (neu!) â† GeÃ¤ndert
- `Input_Betriebskosten_v001.csv` (aktuell)
- `Input_SAP_v001.csv` (aktuell)

**Challenge**: 
Nur `Input_Rabatt_v002.csv` sollte neu geladen werden. Die anderen 3 Inputs kÃ¶nnen aus dem targets-Cache wiederverwendet werden.

### LÃ¶sung: Datei-basierte Targets mit Timestamps

**Architektur**:
```r
# _targets.R Struktur

tar_target(hochrechnung_path, {
  # Finde neueste v* Version in data/raw/
  get_latest_input_path("Input_Hochrechnung")
})

tar_target(hochrechnung, {
  # LÃ¤dt nur neu, wenn hochrechnung_path sich geÃ¤ndert hat
  load_csv(hochrechnung_path)
})

tar_target(rabatt_path, get_latest_input_path("Input_Rabatt"))
tar_target(rabatt, load_csv(rabatt_path))

# ... Ã¤hnlich fÃ¼r betriebskosten und sap

tar_target(inputs_combined, {
  # Kombiniert alle Input-Daten (wird nur neu berechnet wenn mind. ein Input neu ist)
  list(
    hochrechnung = hochrechnung,
    rabatt = rabatt,
    betriebskosten = betriebskosten,
    sap = sap
  )
})

tar_target(validated_inputs, {
  # Validierung greift nur auf geÃ¤nderte Inputs
  result <- validate_all_inputs(inputs_combined)
  if (!result$success) stop(result$errors)
  inputs_combined
})

tar_target(results, {
  # Berechnung - nur wenn Validierung OK
  calculate_budget(validated_inputs)
})

tar_target(report, {
  # Quarto-Report mit Timestamp
  quarto::quarto_render("report.qmd", ...)
})
```

### Implementierungsdetails

**1. Helper-Funktion: `get_latest_input_path()`**
```r
# In R/00_config.R
get_latest_input_path <- function(input_name) {
  # Beispiel input_name = "Input_Rabatt"
  # Sucht: data/raw/Input_Rabatt_v*.csv
  # Gibt zurÃ¼ck: Pfad zur Version mit hÃ¶chster vNN
  
  pattern <- glue::glue("^{input_name}_v\\d+\\.csv$")
  files <- list.files("data/raw", pattern = pattern, full.names = TRUE)
  
  if (length(files) == 0) stop(glue::glue("Keine {input_name} Dateien gefunden"))
  
  # Extrahiere Versionsnummer und sortiere
  versions <- str_extract(files, "\\d+") |> as.numeric()
  files[which.max(versions)]
}
```

**2. Dependency-Tracking**
- `tar_target(hochrechnung_path, ...)` â†’ targets Ã¼berwacht Dateisystem
- Wenn `data/raw/Input_Hochrechnung_v002.csv` hinzukommt â†’ `hochrechnung_path` invalidiert
- `tar_target(hochrechnung, ...)` wird neu berechnet
- `tar_target(rabatt, ...)` bleibt cached (Datei unverÃ¤ndert)

**3. Fehlerbehandlung in der Pipeline**
```r
tar_target(validated_inputs, {
  result <- validate_all_inputs(inputs_combined)
  if (!result$success) {
    # targets stoppt Pipeline mit Fehler
    stop(glue::glue(
      "Validierung fehlgeschlagen:\n{paste(result$errors, collapse = '\n')}"
    ))
  }
  inputs_combined
})
```

---

## Meilensteine

### âœ… Phase 1: Core-Funktionen (FERTIG)
- [x] `R/00_config.R` â€“ Konstanten & Validierungsregeln
- [x] `R/01_load_data.R` â€“ CSV-Laden mit Error-Handling
- [x] `R/02_validate_data.R` â€“ pointblanc-Validierung
- [x] `R/03_calculate.R` â€“ Formelwerk-Implementierung
- [x] Dummy-Daten (v1 & v2) generiert

**Status**: âœ… Alle Funktionen sind produktionsreif

---

### âœ… Phase 2: targets-Pipeline (IN ARBEIT)
- [x] `_targets.R` â€“ DAG-Definition implementiert
  - [x] `get_latest_input_path()` implementiert
  - [x] File-basierte Targets fÃ¼r alle 4 Inputs
  - [x] `inputs_combined` Target
  - [x] `validated_inputs` Target mit Warning-Handling
  - [x] `berechnung` Target
  - [x] `output_file` Target
- [x] Integration mit bestehenden R-Funktionen getestet
- [ ] Partial-Update Szenario: Validierung ausstehend
- [ ] targets-DAG Fehlerbehandlung optimieren
- [ ] Alle Test-Szenarien erfolgreich durchlaufen

**Status**: ğŸ”„ **IN ARBEIT â€“ Tests teils erfolgreich, Optimierungen notwendig**

**Test-Ergebnisse**:
```
# Aktuelle Test-Ergebnisse (Partial Update)

1. âœ… tar_make() mit v1 aller Inputs â†’ Alle Targets berechnet
2. âœ… Input_Rabatt_v002.csv hinzufÃ¼gen
3. âœ… tar_make() â†’ Nur rabatt* Targets invalidiert, andere gecacht
4. âš ï¸ Validierung bei Partial Update: Warnung statt Fehler
5. âŒ Berechnung bei fehlendem SAP_v002: Mismatch in Datenstruktur
```

**NÃ¤chste Schritte**:
- Validierungslogik fÃ¼r Partial Updates verfeinern
- SAP-Daten Handling bei unterschiedlichen Versionen testen
- Fehlerbehandlung in Combined Inputs robuster machen

---

### ğŸ¨ Phase 3: Shiny Dashboard (AKTUELL)
- [x] `app.R` â€“ Main Shiny Application
- [x] `R/shiny_helpers.R` â€“ Helper-Funktionen
- [x] Dashboard Tab: KPI-Ãœbersicht & Visualisierungen
- [x] Upload Tab: Neue Inputdateien hochladen
- [x] Pipeline Control: tar_make() Trigger
- [ ] **Versions-Vergleich Tab**: Alt vs. Neu Vergleiche
- [ ] **Audit-Trail Tab**: Ã„nderungs-Historie anzeigen
- [ ] **Validierungs-Details Tab**: pointblanc-Fehler visualisieren
- [ ] Export: Vergleichsberichte (PDF/HTML)

**Features zur Implementierung**:

1. **Versions-Historie**
   - Zeige alle verfÃ¼gbaren Input-Versionen in Dropdown
   - Verlade alte CSV-Versionen aus `data/raw/`
   - Berechne KPIs fÃ¼r beide Versionen (alt & neu)
   - Side-by-Side Vergleich mit Differenzen farblich markiert

2. **Unterschieds-Visualisierung**
   - Tabelle mit alten & neuen Werten
   - Spalten-weise Differenzen (Betrag & Prozent)
   - Highlight der wichtigsten Ã„nderungen (SQ, CR)
   - Tooltip mit ErklÃ¤rung der Ã„nderungen

3. **Audit-Trail**
   - Chronologische Liste aller Input-Versionen
   - Timestamps & DateigrÃ¶ÃŸen
   - Wer hat die Datei hochgeladen (optional, wenn User-Track vorhanden)
   - Download-Links zu alten Outputs

4. **Validierungs-Details** (mit pointblanc)
   - Zeige alle ValidierungsprÃ¼fungen an
   - âœ… Bestandene Regeln grÃ¼n
   - âŒ Fehlgeschlagene Regeln rot mit BegrÃ¼ndung
   - âš ï¸ Warnungen gelb
   - Details pro Product-ID bei Fehler

**Notiz zu pointblanc**: 
- pointblanc wird **NICHT** fÃ¼r Visualisierung verwendet
- pointblanc ist fÃ¼r **Daten-Validierung** (RegelprÃ¼fung)
- Visualisierung nutzt: ggplot2, plotly, reactable (fÃ¼r Tabellen)
- Validierungsergebnisse werden dann visualisiert (als Text/Farben/Icons)

---

### ğŸ¯ Phase 4: Polish & Demo (AUSSTEHEND)
- [ ] README schreiben (fÃ¼r Stakeholder)
- [ ] Mock-Fehlerfall testen (z.B. Rabatt > 100%)
- [ ] targets-DAG Screenshot fÃ¼r Pitch
- [ ] Final Test: Full Workflow v1 â†’ v2
- [ ] Shiny-Performance bei groÃŸen Datenmengen testen
- [ ] Error-Handling fÃ¼r fehlende alte Versionen

---

## Validierungsregeln (pointblanc)

### Data Quality
- âœ… Pflicht-Spalten vorhanden
- âœ… Datentypen korrekt
- âœ… Keine NAs in Pflicht-Spalten
- âœ… Keine Duplikate bei product_id
- âœ… Alle 5 Produkte vorhanden

### Business Rules
- âœ… `bestand > 0`
- âœ… `bvp > 0`
- âœ… `fam_rab + mj_rab < 100` (Rabatte < 100%)
- âœ… `sm` zwischen 0.5 und 1.5
- âœ… `bk >= 0`

---

## Testing-Strategie

### âš ï¸ Test-Ordner: Read-Only fÃ¼r Pipeline

**Wichtig**: Der `test/`-Ordner wird von Pipeline-Ã„nderungen NICHT beeinflusst:
- âœ… Tests laufen unabhÃ¤ngig von `_targets.R`
- âœ… Input-Versionierung triggert KEINE Test-Updates
- âœ… `tar_make()` verÃ¤ndert niemals Dateien in `test/`
- âœ… Test-Fehler stoppen Pipeline NICHT (separate CI/CD)

**Konsequenz**: Wenn Tests aktualisiert werden mÃ¼ssen â†’ Manuell im `test/`-Ordner bearbeiten, nicht automatisiert.

### Unit Tests (testthat)
- `test/test_01_load_data.R` â€“ CSV-Laden
- `test/test_02_validate_data.R` â€“ Validierungsregeln
- `test/test_03_calculate.R` â€“ Formelwerk
- `test/test_workflow.R` â€“ Load â†’ Validate â†’ Calculate

### Integration Tests
- `test/test_pipeline_1.R` â€“ targets-Caching & Partial Updates
- Laufen separat: `source("test/test_pipeline_1.R")`
- Nicht Teil von `tar_make()`

---

## Status

ğŸ”„ **Phase 1 âœ… â†’ Phase 2 IN ARBEIT**: targets-Pipeline mit intelligentem Caching wird optimiert

---

## Glossar

- **Versionierung**: `Input_<Name>_v<NN>.csv` (z.B. v001, v002, v003)
- **Caching**: targets speichert Rechenergebnisse; nur geÃ¤nderte Inputs triggern Neuberechnung
- **Partial Update**: Nur ein oder mehrere (nicht alle) Inputdateien sind neu
- **DAG**: Directed Acyclic Graph (targets zeigt AbhÃ¤ngigkeiten)
- **pointblanc**: R-Package fÃ¼r Datenvalidation mit Custom Rules