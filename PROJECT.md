# PROJECT.md - Budget & Hochrechnung Automation PoC

## Projektziel
Pitch am Montag fÃ¼r LÃ¶sungsvorschlag zur Vereinfachung von Hochrechnungs- und Budget-Prozessen.
- **Problem**: Manueller Excel-Austausch, ineffizient, nicht nachvollziehbar
- **LÃ¶sung**: Automatisierte Pipeline (targets) mit validierter Datenverarbeitung
- **MVP**: FunktionsfÃ¤hige targets-Pipeline + Quarto-Report + validierte Kernfunktionen

---

## Datenmodell

### Produkte (Join-Key fÃ¼r alle Inputs)
**Ambulant**: `Amb_T`, `Amb_S`, `Amb_C`  
**StationÃ¤r**: `Hosp_P`, `Hosp_HP`

### Input-Dateien (v1 = Standard)

| Datei | Spalten | Beschreibung |
|-------|---------|-------------|
| `Input_Hochrechnung.csv` | `product_id`, `bestand`, `bvp`, `nvl` | Ist-Bestand, Betrag pro Versicherte & Schadenwert |
| `Input_Rabatt.csv` | `product_id`, `fam_rab`, `mj_rab` | Familienrabatt & MehrjÃ¤hrig-Rabatt (%) |
| `Input_Betriebskosten.csv` | `product_id`, `sm`, `bk` | Saison-Multiplikator & Betriebskosten |
| `Input_SAP.csv` | `product_id`, `advo`, `pd`, `sap` | Ist-Daten (Advocacy, Pd, SAP-Betrag) |

### Formelwerk

```
nvp = bvp - (fam_rab + mj_rab)           # Netto-VersicherungsprÃ¤mie
SQ = nvl / nvp                            # Schadenquote (Ziel: 60-80%)
vp = nvp - advo - pd                      # Verdiente PrÃ¤mie
va = nvl + sap + sm                       # Versicherungs-Aufwand
CR = (va + bk) / vp                       # Combined Ratio (Ziel: 85-105%)
```

---

## Workflow & Use-Case

### Standard-Flow
1. **Input (v1)**: 4 CSV-Dateien vorhanden
2. **Validierung**: pointblanc prÃ¼ft DatenqualitÃ¤t
   - Wenn **Fehler**: Abbruch mit aussagekrÃ¤ftigen Fehlermeldungen
   - Wenn **OK**: Weiter zu Berechnung
3. **Berechnung**: targets-Pipeline berechnet nvp, SQ, vp, va, CR
4. **Output**: Quarto-Report mit:
   - Zusammenfassung (Tabelle mit allen KPIs pro Produkt)
   - Analysen (CR-Verteilung, SQ-Analyse, SAP-Vergleich)
   - Download-Link zu Rohdaten

### v2-Szenario (Demo)
- Fehlerhafte v1 wird behoben â†’ v2 hochgeladen
- targets-Pipeline lÃ¤uft erneut
- **Caching**: UnverÃ¤nderte Inputs werden wiederverwendet

---

## Architektur & Tech-Stack

### PoC (aktuell, GitHub)
- **Versionskontrolle**: GitHub
- **Datenvalidation**: pointblanc (Custom Rules)
- **Workflow-Orchestrierung**: `targets` (DAG + Caching)
- **Output-Format**: Quarto (.qmd â†’ HTML/PDF Report)
- **Testing**: testthat fÃ¼r Rechenfunktionen + Validierung

### Finale Umsetzung (falls akzeptiert)
- Git: Azure DevOps
- Compute: Posit Workbench
- Deployment: Posit Connect (Automatische Report-Generierung)

---

## Meilensteine (4h Zeitbudget)

### Phase 1: Setup & Datenstruktur (30min) âœ…
- [x] Ordnerstruktur erstellt
- [x] Dummy-Daten generiert (v1 + v2)
- [x] Formelwerk definiert

**Status**: âœ… Abgeschlossen

---

### Phase 2: Core-Funktionen & Tests (90min) âœ…
- [x] `R/01_load_data.R` â€“ CSV-Laden mit Error-Handling
- [x] `R/02_validate_data.R` â€“ Validierungsregeln
- [x] `R/03_calculate.R` â€“ Formelwerk-Implementierung
- [x] `_targets.R` â€“ Data-Pipeline funktionsfÃ¤hig
- [x] Validierung in targets integriert
- [x] Tests inline (in _targets.R)

**Status**: âœ… Abgeschlossen â€“ Pipeline lÃ¤uft erfolgreich!

---

### Phase 3: Quarto-Report & Shiny-Dashboard (60min) ğŸŸ¡
- [x] `report.qmd` â€“ Quarto-Report Template erstellt
- [ ] `app.R` â€“ Shiny-Dashboard fÃ¼r Versions-Vergleich
- [ ] targets-Pipeline mit Report testen
- [ ] Shiny-App starten und testen

**Status**: ğŸŸ¡ In Arbeit â€“ Report-Template vorhanden, Shiny folgt

---

### Phase 4: Polish & Demo (40min) â³
- [ ] targets-DAG Screenshot fÃ¼r Pitch
- [ ] README schreiben
- [ ] Mock-Fehlerfall testen
- [ ] Final Test vor Pitch

**Status**: â³ Ausstehend

---

## Validierungsregeln (pointblanc)

Folgende **Validierungen** mÃ¼ssen greifen:

### Data Quality
- âœ… Pflicht-Spalten vorhanden (je nach File)
- âœ… Datentypen korrekt: `product_id` = char, numerische Spalten = dbl
- âœ… Keine NAs in Pflicht-Spalten
- âœ… Keine Duplikate bei product_id

### Business Rules
- âœ… `bestand > 0`
- âœ… `bvp > 0`
- âœ… `fam_rab + mj_rab < 100` (Rabatte nicht > 100%)
- âœ… `sm` zwischen 0.5 und 1.5 (sinnvoller Bereich)
- âœ… `bk >= 0`
- âœ… Alle 5 Produkte (Amb_T, Amb_S, Amb_C, Hosp_P, Hosp_HP) vorhanden

### Error Messages
- Klar strukturiert
- Nennt konkret welche Spalte/Zeile/Produkt fehlerhaft ist
- Suggeriert Behebung (z.B. "Rabatte kÃ¶nnen nicht > 100% sein")

---

## Testing-Strategie

### Unit Tests (testthat) fÃ¼r Core-Funktionen
Dateien in `tests/testthat/`:

**test_01_load_data.R** â€“ CSV-Laden testen:
- CSV wird korrekt geladen (Spalten, Zeilen)
- Datentypen werden korrekt interpretiert
- Error-Handling bei fehlenden Dateien

**test_02_validate_data.R** â€“ pointblanc Regeln testen:
- Data Quality Checks (Spalten, NAs, Duplikate)
- Business Rule Checks (Rabatte, SM-Range, alle Produkte)
- AussagekrÃ¤ftige Error-Messages

**test_03_calculate.R** â€“ Formelwerk testen:
- `nvp` korrekt berechnet (nvp = bvp - (fam_rab + mj_rab))
- `SQ` korrekt berechnet (SQ = nvl / nvp)
- `vp` korrekt berechnet (vp = nvp - advo - pd)
- `va` korrekt berechnet (va = nvl + sap + sm)
- `CR` korrekt berechnet (CR = (va + bk) / vp)
- Edge Cases (Division by zero, negative values)

### Workflow Tests
`tests/testthat/test_workflow.R` â€“ Load â†’ Validate â†’ Calculate:
- v1 (gÃ¼ltig) â†’ Validierung OK â†’ Berechnung erfolgreich
- v1 (Fehler) â†’ Validierung schlÃ¤gt fehl â†’ Error-Message
- v2 (behoben) â†’ Validierung OK â†’ Berechnung erfolgreich

---

## Status
ğŸŸ¡ **Phase 1 abgeschlossen** â†’ Phase 2: Core-Funktionen implementieren + testen

---

## Notizen fÃ¼r Debugging/Pitch
- targets-DAG Screenshot vor Pitch testen!
- Mock-Fehlerfall (CSV mit absichtlichen Fehlern) vorbereiten
- Report sollte auch bei kleinen Datenmengen aussagekrÃ¤ftig sein
- pointblanc Rules mÃ¼ssen aussagekrÃ¤ftige Errors werfen
- README fÃ¼r Stakeholder schreiben (nicht nur Entwickler)